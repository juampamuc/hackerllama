{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "date: \"01/01/2024\"\n",
    "twitter-card: true\n",
    "title: The Random Transformer\n",
    "description: Understand how transformers work by demystifying all the math behind them\n",
    "toc-depth: 5\n",
    "format:\n",
    "  html:\n",
    "    comments:\n",
    "      utterances:\n",
    "         repo: osanseviero/hackerllama\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: sentence_transformers in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (4.34.1)\n",
      "Requirement already satisfied: tqdm in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (0.15.2+cu118)\n",
      "Requirement already satisfied: numpy in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.9.2)\n",
      "Requirement already satisfied: requests in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.27.5)\n",
      "Requirement already satisfied: lit in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\n",
      "Requirement already satisfied: click in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.5)\n",
      "Requirement already satisfied: joblib in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/osanseviero/miniconda3/envs/book/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6003]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentences = [\"I'm happy\", \"I'm full of happiness\"]\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embedding for both lists\n",
    "embedding_1 = model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from https://faq.ssa.gov/en-US/topic/?id=CAT-01092\n",
    "\n",
    "faq = {\n",
    "    \"How do I get a replacement Medicare card?\": \"If your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov.\",\n",
    "    \"How do I sign up for Medicare?\": \"If you already get Social Security benefits, you do not need to sign up for Medicare. We will automatically enroll you in Original Medicare (Part A and Part B) when you become eligible. We will mail you the information a few months before you become eligible.\",\n",
    "    \"What are Medicare late enrollment penalties?\": \"In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\",\n",
    "    \"Will my Medicare premiums be higher because of my higher income?\": \"Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\",\n",
    "    \"What is Medicare and who can get it?\": \"Medicare is a health insurance program for people age 65 or older. Some younger people are eligible for Medicare including people with disabilities, permanent kidney failure and amyotrophic lateral sclerosis (Lou Gehrig’s disease or ALS). Medicare helps with the cost of health care, but it does not cover all medical expenses or the cost of most long-term care.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 384])\n"
     ]
    }
   ],
   "source": [
    "corpus_embeddings = model.encode(list(faq.values()), convert_to_tensor=True)\n",
    "print(corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = \"Do I need to pay more after a raise?\"\n",
    "query_embedding = model.encode(user_question, convert_to_tensor=True)\n",
    "query_embedding.shape\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 question (p=0.35796284675598145): Will my Medicare premiums be higher because of my higher income?\n",
      "Answer: Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\n",
      "Top 2 question (p=0.2787758708000183): What are Medicare late enrollment penalties?\n",
      "Answer: In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\n",
      "Top 3 question (p=0.15840473771095276): How do I sign up for Medicare?\n",
      "Answer: If you already get Social Security benefits, you do not need to sign up for Medicare. We will automatically enroll you in Original Medicare (Part A and Part B) when you become eligible. We will mail you the information a few months before you become eligible.\n"
     ]
    }
   ],
   "source": [
    "similarities = util.semantic_search(\n",
    "    query_embedding, corpus_embeddings, top_k=3\n",
    ")[0]\n",
    "for i, result in enumerate(similarities):\n",
    "    corpus_id = result[\"corpus_id\"]\n",
    "    score = result[\"score\"]\n",
    "    print(f\"Top {i+1} question (p={score}): {list(faq.keys())[corpus_id]}\")\n",
    "    print(f\"Answer: {list(faq.values())[corpus_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 2019, 2742, 6251,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer('This is an example sentence', return_tensors='pt')\n",
    "encoded_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0366, -0.0162,  0.1682,  ...,  0.0554, -0.1644, -0.2967],\n",
       "         [ 0.7239,  0.6399,  0.1888,  ...,  0.5946,  0.6206,  0.4897],\n",
       "         [ 0.0064,  0.0203,  0.0448,  ...,  0.3464,  1.3170, -0.1670],\n",
       "         ...,\n",
       "         [ 0.1479, -0.0643,  0.1457,  ...,  0.8837, -0.3316,  0.2975],\n",
       "         [ 0.5212,  0.6563,  0.5607,  ..., -0.0399,  0.0412, -1.4036],\n",
       "         [ 1.0824,  0.7140,  0.3986,  ..., -0.2301,  0.3243, -1.0313]]]), pooler_output=tensor([[ 1.3429e-02,  4.0036e-02,  3.0797e-03,  7.7094e-03, -8.5741e-02,\n",
       "         -3.2874e-02,  4.5395e-02,  5.4421e-02, -6.6219e-02, -3.3736e-02,\n",
       "         -7.4499e-03,  3.3775e-02, -1.8523e-02, -1.2477e-02, -6.1699e-02,\n",
       "          7.9306e-02,  9.3979e-02, -2.9625e-02, -1.4692e-02,  5.6033e-02,\n",
       "          1.1484e-02,  1.1056e-02,  2.2872e-02, -2.9034e-02, -1.8243e-02,\n",
       "          1.3069e-01, -2.4484e-02,  5.1790e-02,  3.6784e-02,  8.1075e-02,\n",
       "          8.6604e-02,  3.3905e-04, -6.8685e-02,  3.2757e-02,  2.5933e-03,\n",
       "         -4.3434e-02, -1.7191e-02,  8.2270e-02, -4.7278e-02, -3.3682e-02,\n",
       "          6.5672e-02,  2.9311e-02, -5.9559e-02,  7.0777e-02, -1.5764e-02,\n",
       "          2.1118e-02, -1.0806e-01, -3.4479e-02, -4.8619e-02,  4.2684e-02,\n",
       "         -1.2006e-01,  4.6358e-02,  1.5641e-02, -9.6469e-03, -3.7291e-02,\n",
       "          3.7824e-02,  3.4880e-02, -1.5224e-02,  5.4148e-02,  2.4613e-02,\n",
       "          1.5847e-02, -2.4202e-02, -2.2713e-03, -7.8122e-03, -9.2186e-02,\n",
       "          4.1878e-03, -5.9705e-02, -1.0853e-01, -3.1122e-02, -2.0779e-02,\n",
       "         -3.8755e-02,  2.9059e-02, -4.6478e-02, -2.9519e-03,  2.0831e-02,\n",
       "          5.2982e-02, -4.9873e-02,  2.5957e-02, -6.8848e-02, -9.3445e-04,\n",
       "          9.7473e-03,  3.8063e-02,  6.7740e-02, -1.2013e-01, -4.9044e-02,\n",
       "         -7.2494e-02, -5.4891e-02,  4.2310e-02, -7.8359e-03,  7.4343e-02,\n",
       "          4.2601e-02,  1.1231e-02, -1.3430e-01,  5.6985e-02,  8.3218e-02,\n",
       "         -2.5391e-02, -6.5197e-03, -5.7111e-02, -1.7963e-01, -4.5549e-03,\n",
       "          7.8273e-02, -9.1694e-03, -2.6726e-02,  2.8545e-02, -2.9945e-03,\n",
       "         -8.1081e-02, -1.1999e-02,  7.7119e-02, -2.2280e-02,  3.5329e-02,\n",
       "          9.1938e-02,  2.5805e-02,  4.1517e-02,  1.5394e-02, -4.7167e-02,\n",
       "          7.5881e-02, -1.8906e-02, -3.8819e-02, -1.1037e-01,  6.3771e-02,\n",
       "          1.2736e-01, -4.3087e-02,  6.0566e-02,  4.5662e-02,  1.2671e-02,\n",
       "          1.6946e-03,  4.5216e-02, -6.5698e-02, -9.2475e-02, -4.4247e-02,\n",
       "          1.1738e-01, -4.1540e-02,  9.1604e-02, -1.2345e-01, -6.4776e-02,\n",
       "          5.9695e-02, -4.8307e-02, -1.9186e-02, -4.8370e-02,  8.4520e-02,\n",
       "          6.1380e-02, -1.3651e-01,  4.2905e-02, -3.0625e-02,  7.8972e-02,\n",
       "          1.2373e-02, -7.8566e-02, -1.1315e-01,  2.2296e-03, -2.0005e-02,\n",
       "          7.4801e-02, -7.9967e-02, -9.2751e-02,  4.6135e-02,  4.7489e-03,\n",
       "          1.9638e-02,  3.5892e-02, -2.1168e-02, -1.0492e-02, -5.3379e-02,\n",
       "         -4.8980e-02, -7.6467e-02,  8.6475e-02,  1.7718e-02, -5.9111e-02,\n",
       "          2.3288e-02,  2.2532e-02, -3.4328e-02, -2.9752e-02, -6.2305e-02,\n",
       "         -8.1938e-02,  1.7710e-02, -4.8280e-02, -6.2486e-02,  3.1141e-02,\n",
       "          2.3507e-02,  5.2303e-02, -6.9293e-02,  1.1098e-02, -2.0867e-02,\n",
       "          5.7609e-02, -1.0762e-01, -6.3090e-02, -3.2820e-02,  5.2514e-02,\n",
       "          3.2342e-02,  3.6938e-02,  7.0675e-02,  1.0392e-01, -5.7706e-02,\n",
       "          1.6733e-02,  1.4690e-02,  2.7245e-02,  5.0453e-02, -8.0111e-03,\n",
       "         -3.9295e-02, -7.9695e-02,  1.6183e-02,  2.3606e-02,  1.4193e-02,\n",
       "          1.6472e-02,  7.4927e-02, -4.1723e-03,  4.2714e-02, -1.2629e-02,\n",
       "         -2.7271e-02, -6.2421e-02, -1.4004e-01, -2.9299e-02,  1.6869e-02,\n",
       "          6.9726e-02,  2.7200e-02, -4.3012e-02, -3.9393e-02, -6.9088e-02,\n",
       "         -5.2691e-02,  8.2750e-02,  7.5312e-02,  8.0191e-02, -1.2825e-02,\n",
       "          4.1995e-02, -1.2516e-02,  2.7372e-02, -1.2028e-01, -1.2387e-01,\n",
       "         -5.4954e-02, -6.5397e-03, -6.6795e-02,  1.3161e-02,  2.2269e-02,\n",
       "         -2.9861e-02,  7.6297e-02,  2.7364e-02,  1.0883e-01, -8.8141e-03,\n",
       "          8.6819e-02, -2.4719e-02, -4.9682e-02,  5.1936e-02,  3.4862e-02,\n",
       "         -1.2001e-01,  8.3150e-02, -2.0191e-02, -5.3333e-03, -7.3319e-02,\n",
       "          4.7377e-02,  6.8626e-02,  5.7092e-02,  1.0385e-02, -3.3254e-02,\n",
       "          1.5860e-02,  1.5843e-02,  3.2043e-03,  3.3453e-02, -2.3586e-02,\n",
       "          5.4750e-02,  2.8557e-02, -2.5185e-02,  2.1314e-02,  3.8470e-02,\n",
       "          4.0113e-02,  1.6145e-02, -5.4575e-02, -1.4632e-03, -4.4623e-02,\n",
       "          2.8726e-02,  1.1302e-01, -4.1902e-02, -1.3932e-02, -9.6624e-02,\n",
       "          1.8770e-02,  9.0820e-03, -8.1532e-02, -8.8747e-03,  1.0511e-01,\n",
       "          2.2679e-02,  2.5884e-02, -7.2527e-02,  6.1241e-02, -1.5532e-02,\n",
       "          1.4980e-02,  5.6270e-02,  6.3009e-02, -4.2786e-02,  7.4515e-02,\n",
       "         -2.7271e-02,  4.7316e-02, -2.8739e-02,  4.9152e-02,  8.2691e-02,\n",
       "          1.2656e-02, -2.7052e-02, -4.3005e-02,  9.0674e-03, -5.3151e-02,\n",
       "          6.2785e-02,  3.9300e-02,  6.7608e-02, -8.9390e-03,  3.2900e-02,\n",
       "         -3.2308e-02, -3.5465e-02,  7.5596e-02, -2.9816e-02, -3.6290e-02,\n",
       "          1.5477e-02, -4.8453e-02,  7.6024e-03,  3.5700e-02,  1.4346e-02,\n",
       "          8.0476e-02,  6.1430e-02,  5.6743e-03,  1.1575e-02, -4.4946e-02,\n",
       "         -3.3531e-02,  1.4398e-02, -1.3222e-01, -4.2706e-03, -3.7443e-02,\n",
       "         -1.4443e-02, -7.8702e-02,  2.7131e-02,  6.0028e-02,  5.8510e-02,\n",
       "         -1.2206e-02,  2.7320e-02,  3.1169e-02, -4.1544e-02, -2.1317e-02,\n",
       "          1.6517e-02, -2.7584e-02,  3.4797e-02,  4.2613e-02,  1.3636e-03,\n",
       "         -8.5100e-02,  3.7460e-02,  4.3458e-02, -9.4549e-03,  3.9982e-02,\n",
       "          4.2519e-02, -8.8832e-02, -7.8078e-03, -1.1596e-01,  9.5078e-02,\n",
       "         -9.7206e-02,  6.5254e-02,  2.9393e-02,  3.7238e-03, -2.1312e-02,\n",
       "          1.9388e-02, -5.0150e-02,  6.9220e-02, -1.0495e-02, -2.4837e-02,\n",
       "         -7.5547e-02, -2.7963e-02, -2.5091e-03,  6.8878e-02, -4.4469e-02,\n",
       "         -3.9632e-02, -1.1323e-02, -5.2578e-02, -8.7117e-02,  2.7642e-02,\n",
       "         -4.9512e-02,  2.0677e-02, -1.1490e-02,  1.2818e-02,  2.9686e-02,\n",
       "         -1.0459e-01,  5.0408e-02,  1.0962e-01,  4.6272e-02, -1.1502e-04,\n",
       "          6.5767e-03, -8.2945e-02,  5.0269e-02, -5.0819e-02, -6.9119e-02,\n",
       "          6.4439e-02,  3.8906e-02, -6.8270e-02, -9.6023e-03]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4935e-01,  3.2786e-01,  2.5153e-01,  4.0949e-01,  1.9336e-01,\n",
       "          1.3698e-02,  2.0331e-01, -3.6653e-02,  3.0651e-01,  1.6284e-01,\n",
       "          3.1032e-01, -2.7318e-01,  2.0967e-01, -1.3389e-01,  1.5409e-01,\n",
       "          5.8186e-03,  3.7959e-01, -2.6015e-01, -6.3194e-01,  1.2239e-01,\n",
       "          1.5349e-01,  2.1933e-01,  1.3236e-01,  1.0302e-02, -2.9390e-01,\n",
       "         -1.4024e-01, -1.6990e-01,  3.4092e-01,  6.1449e-01, -2.3690e-01,\n",
       "         -3.7498e-01, -1.6825e-01,  2.7026e-01,  2.3264e-01,  4.2614e-02,\n",
       "          1.8951e-01, -7.1987e-02,  3.3765e-01, -1.3646e-01,  1.0659e-03,\n",
       "         -7.0556e-02, -1.8734e-01, -1.0071e-01, -1.4961e-01,  2.0358e-01,\n",
       "         -4.5650e-01,  1.3550e-02,  7.0592e-02,  2.4943e-01, -1.6088e-01,\n",
       "         -6.0583e-01, -2.6421e-01, -4.5712e-01, -1.1306e-01,  7.3831e-02,\n",
       "          2.2935e-01, -6.9612e-02,  3.8385e-01,  1.3755e-01, -1.0263e-01,\n",
       "          9.2525e-02, -5.4760e-02, -4.6691e-01,  1.1012e-01,  7.2911e-01,\n",
       "         -3.3417e-02, -7.2486e-03, -7.9316e-02, -4.5107e-01,  3.7289e-01,\n",
       "          1.0399e-01,  2.1975e-01, -1.8021e-01,  1.6499e-03, -4.1461e-01,\n",
       "         -1.6909e-01,  1.4730e-01, -2.6523e-01,  5.6483e-01,  4.2306e-01,\n",
       "         -5.0811e-01, -4.8232e-01, -7.8119e-02,  2.3300e-01,  2.5517e-01,\n",
       "         -1.3005e-01,  8.1106e-02, -6.6759e-01,  2.7464e-02,  2.0775e-02,\n",
       "         -1.2112e-01, -3.4749e-01,  1.5092e-01, -1.3469e-01,  6.7448e-02,\n",
       "         -1.6093e-01, -2.4925e-01, -2.8857e-01, -2.0009e-01,  6.1967e-01,\n",
       "         -5.3661e-02,  2.5286e-01,  2.8582e-01,  2.3203e-01, -2.0704e-02,\n",
       "         -5.3163e-01, -1.5127e-01, -3.0124e-01,  1.3966e-01, -1.1368e-01,\n",
       "         -3.7293e-01, -2.1370e-01, -9.9809e-02,  1.4113e-02,  1.4303e-03,\n",
       "         -4.9961e-01, -5.1932e-01, -7.3282e-02, -4.1715e-01,  2.3438e-01,\n",
       "          1.2653e-01,  3.0858e-01, -3.8116e-01,  6.1881e-02, -3.4255e-01,\n",
       "         -3.9710e-01,  1.9888e-01, -2.8883e-32,  1.4458e-01, -2.8956e-01,\n",
       "         -2.5126e-01,  1.1131e-01,  3.1083e-01, -2.4857e-01, -1.8085e-01,\n",
       "          9.9818e-02, -9.0440e-02, -2.0097e-01, -1.9676e-02, -8.7928e-02,\n",
       "          1.4566e-01,  6.6243e-02,  2.4351e-01,  3.2067e-01, -3.3232e-01,\n",
       "          6.6756e-01, -6.7761e-02,  2.7009e-01, -1.9295e-01,  1.4927e-01,\n",
       "         -8.7253e-02, -1.2255e-01, -1.7220e-01, -2.6683e-01,  8.0218e-02,\n",
       "          1.0781e-01, -6.4736e-02,  2.3730e-01,  1.9245e-01,  1.4487e-01,\n",
       "         -3.0465e-01, -6.0407e-02,  2.5414e-01,  2.4285e-01,  3.7977e-01,\n",
       "         -1.9132e-01,  2.0575e-02,  5.4946e-02, -8.3381e-04, -2.7220e-01,\n",
       "          1.4247e-01, -2.0288e-01,  4.3617e-01,  2.5139e-01, -2.5088e-02,\n",
       "          9.2916e-02, -2.2129e-01,  6.3705e-02,  3.3044e-02,  2.0903e-01,\n",
       "          7.6877e-02, -7.9487e-02,  3.9395e-01,  1.2240e-01,  2.2990e-01,\n",
       "          2.6241e-01, -1.1941e-02, -9.7454e-02, -6.3684e-02,  2.4062e-01,\n",
       "         -2.9093e-01,  3.2526e-01, -1.6293e-01,  1.6777e-01,  1.2117e-01,\n",
       "         -3.3843e-01,  1.0415e-01,  1.3274e-01, -6.3960e-02, -4.3192e-02,\n",
       "         -3.4305e-01,  4.8695e-01, -1.8438e-01, -1.7684e-01, -3.4407e-02,\n",
       "         -4.1386e-02, -1.5992e-01,  2.2359e-01, -4.2413e-02, -7.7863e-01,\n",
       "          1.5888e-01,  2.0691e-01, -1.9585e-01,  9.9766e-03,  2.0681e-01,\n",
       "         -4.5288e-01, -1.9027e-01,  4.4301e-02, -1.6485e-01, -6.4677e-02,\n",
       "          3.7979e-01,  6.9572e-03,  1.0633e-01,  1.3998e-32, -2.6777e-01,\n",
       "          2.9864e-01, -4.7452e-01,  2.0366e-01,  5.4514e-01, -1.0168e-01,\n",
       "          3.1931e-01, -3.9421e-01,  1.2438e-01,  4.8539e-01, -6.0173e-01,\n",
       "          1.9167e-01,  2.6975e-01, -2.0440e-02,  2.9546e-01,  2.7514e-02,\n",
       "          6.4036e-01,  7.1784e-02, -5.6927e-02,  1.8385e-01, -1.7078e-01,\n",
       "          4.2164e-01, -7.8487e-02,  3.1269e-01, -3.1053e-01,  1.6838e-01,\n",
       "         -1.7984e-01, -8.7718e-02, -5.0339e-01, -1.4018e-01,  9.0213e-03,\n",
       "         -3.9706e-01, -2.2299e-01, -9.8098e-02, -1.5060e-01,  2.9819e-01,\n",
       "          1.2486e-01, -6.0362e-02, -3.2088e-01,  1.4682e-01, -1.2265e-03,\n",
       "         -1.3001e-01,  2.2701e-02,  4.1971e-01,  1.8805e-01, -3.1188e-01,\n",
       "         -1.8873e-01, -4.0985e-01, -2.6258e-02,  3.4580e-01, -6.0818e-01,\n",
       "          1.6716e-01, -2.4333e-01, -6.9428e-02, -4.8973e-01,  4.2596e-02,\n",
       "         -5.5119e-02, -3.5209e-01,  5.7736e-03,  1.2806e-01, -3.2834e-01,\n",
       "          1.4690e-01, -1.3492e-01,  4.4308e-01,  5.9216e-01, -2.7643e-01,\n",
       "         -2.9101e-01,  2.1997e-01,  5.6517e-02,  1.0822e-01,  5.1703e-01,\n",
       "          1.6836e-01, -9.5116e-01, -2.0303e-01, -3.5703e-01, -3.2948e-01,\n",
       "         -3.3892e-01, -3.3111e-02, -2.4765e-01, -3.9662e-01,  1.5252e-01,\n",
       "         -1.1873e-01,  2.1534e-01, -1.2911e-01, -2.3469e-02, -2.1539e-01,\n",
       "         -6.8308e-02, -3.2961e-01, -1.2727e-02, -7.0914e-02,  8.7251e-02,\n",
       "         -3.2551e-01,  4.6414e-01,  2.1592e-01, -9.5879e-02, -9.3171e-08,\n",
       "         -8.6746e-02, -1.6605e-01,  3.2550e-01, -2.1330e-01,  2.2968e-01,\n",
       "          1.0454e-02,  3.2509e-01, -2.6714e-02, -5.1864e-02, -1.5782e-01,\n",
       "          1.8210e-01,  2.8842e-01, -2.4120e-01,  1.7819e-01,  1.7018e-01,\n",
       "          2.2209e-01,  1.5199e-01, -1.5654e-01, -8.8351e-02,  3.8080e-01,\n",
       "         -2.8291e-01,  1.4329e-01,  3.2022e-02,  8.1997e-02,  1.7710e-01,\n",
       "         -2.6631e-02,  1.2138e-01,  3.8888e-01,  9.9574e-02,  1.7359e-01,\n",
       "          2.6287e-01,  7.8742e-01,  8.4788e-02,  1.3969e-01,  1.9371e-01,\n",
       "          1.1285e-01,  2.9243e-01, -2.0434e-01,  3.6780e-01, -2.7954e-01,\n",
       "          5.3579e-03,  1.0939e-01, -1.8398e-01,  5.6291e-01,  1.4279e-02,\n",
       "          1.6213e-01,  7.1475e-03, -1.7852e-01, -2.3715e-01,  1.4875e-01,\n",
       "          3.7017e-02,  2.5027e-01,  1.3478e-01, -4.8747e-02,  1.4570e-01,\n",
       "          1.8006e-01,  1.9058e-01, -4.4352e-02, -1.8238e-01, -1.2798e-01,\n",
       "         -9.9098e-02,  1.9658e-01,  3.0963e-01, -2.1805e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\"last_hidden_state\"]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.7657e-02,  6.3496e-02,  4.8713e-02,  7.9305e-02,  3.7448e-02,\n",
       "          2.6528e-03,  3.9375e-02, -7.0984e-03,  5.9361e-02,  3.1537e-02,\n",
       "          6.0098e-02, -5.2905e-02,  4.0607e-02, -2.5931e-02,  2.9843e-02,\n",
       "          1.1269e-03,  7.3515e-02, -5.0382e-02, -1.2239e-01,  2.3703e-02,\n",
       "          2.9727e-02,  4.2477e-02,  2.5634e-02,  1.9952e-03, -5.6919e-02,\n",
       "         -2.7160e-02, -3.2904e-02,  6.6025e-02,  1.1901e-01, -4.5879e-02,\n",
       "         -7.2621e-02, -3.2584e-02,  5.2341e-02,  4.5055e-02,  8.2530e-03,\n",
       "          3.6702e-02, -1.3941e-02,  6.5392e-02, -2.6427e-02,  2.0642e-04,\n",
       "         -1.3664e-02, -3.6281e-02, -1.9504e-02, -2.8974e-02,  3.9427e-02,\n",
       "         -8.8409e-02,  2.6243e-03,  1.3671e-02,  4.8306e-02, -3.1157e-02,\n",
       "         -1.1733e-01, -5.1169e-02, -8.8529e-02, -2.1896e-02,  1.4299e-02,\n",
       "          4.4417e-02, -1.3482e-02,  7.4339e-02,  2.6638e-02, -1.9876e-02,\n",
       "          1.7919e-02, -1.0605e-02, -9.0426e-02,  2.1327e-02,  1.4120e-01,\n",
       "         -6.4717e-03, -1.4038e-03, -1.5361e-02, -8.7357e-02,  7.2217e-02,\n",
       "          2.0140e-02,  4.2559e-02, -3.4901e-02,  3.1953e-04, -8.0297e-02,\n",
       "         -3.2747e-02,  2.8527e-02, -5.1366e-02,  1.0939e-01,  8.1933e-02,\n",
       "         -9.8404e-02, -9.3410e-02, -1.5129e-02,  4.5125e-02,  4.9417e-02,\n",
       "         -2.5187e-02,  1.5708e-02, -1.2929e-01,  5.3189e-03,  4.0234e-03,\n",
       "         -2.3457e-02, -6.7298e-02,  2.9228e-02, -2.6085e-02,  1.3063e-02,\n",
       "         -3.1166e-02, -4.8271e-02, -5.5886e-02, -3.8751e-02,  1.2001e-01,\n",
       "         -1.0392e-02,  4.8971e-02,  5.5354e-02,  4.4936e-02, -4.0098e-03,\n",
       "         -1.0296e-01, -2.9297e-02, -5.8340e-02,  2.7047e-02, -2.2017e-02,\n",
       "         -7.2224e-02, -4.1387e-02, -1.9330e-02,  2.7333e-03,  2.7700e-04,\n",
       "         -9.6759e-02, -1.0057e-01, -1.4192e-02, -8.0789e-02,  4.5393e-02,\n",
       "          2.4504e-02,  5.9761e-02, -7.3818e-02,  1.1984e-02, -6.6340e-02,\n",
       "         -7.6904e-02,  3.8516e-02, -5.5936e-33,  2.8001e-02, -5.6079e-02,\n",
       "         -4.8660e-02,  2.1557e-02,  6.0198e-02, -4.8140e-02, -3.5025e-02,\n",
       "          1.9331e-02, -1.7515e-02, -3.8921e-02, -3.8106e-03, -1.7029e-02,\n",
       "          2.8210e-02,  1.2829e-02,  4.7160e-02,  6.2103e-02, -6.4359e-02,\n",
       "          1.2929e-01, -1.3123e-02,  5.2307e-02, -3.7368e-02,  2.8909e-02,\n",
       "         -1.6898e-02, -2.3733e-02, -3.3349e-02, -5.1676e-02,  1.5536e-02,\n",
       "          2.0880e-02, -1.2537e-02,  4.5958e-02,  3.7272e-02,  2.8057e-02,\n",
       "         -5.9000e-02, -1.1699e-02,  4.9218e-02,  4.7033e-02,  7.3549e-02,\n",
       "         -3.7053e-02,  3.9846e-03,  1.0641e-02, -1.6148e-04, -5.2717e-02,\n",
       "          2.7593e-02, -3.9292e-02,  8.4472e-02,  4.8686e-02, -4.8588e-03,\n",
       "          1.7995e-02, -4.2857e-02,  1.2338e-02,  6.3996e-03,  4.0482e-02,\n",
       "          1.4889e-02, -1.5394e-02,  7.6295e-02,  2.3704e-02,  4.4524e-02,\n",
       "          5.0820e-02, -2.3125e-03, -1.8874e-02, -1.2334e-02,  4.6600e-02,\n",
       "         -5.6344e-02,  6.2993e-02, -3.1554e-02,  3.2491e-02,  2.3467e-02,\n",
       "         -6.5544e-02,  2.0171e-02,  2.5708e-02, -1.2387e-02, -8.3649e-03,\n",
       "         -6.6438e-02,  9.4307e-02, -3.5709e-02, -3.4248e-02, -6.6636e-03,\n",
       "         -8.0152e-03, -3.0971e-02,  4.3301e-02, -8.2140e-03, -1.5080e-01,\n",
       "          3.0769e-02,  4.0072e-02, -3.7929e-02,  1.9321e-03,  4.0053e-02,\n",
       "         -8.7708e-02, -3.6849e-02,  8.5796e-03, -3.1925e-02, -1.2526e-02,\n",
       "          7.3554e-02,  1.3474e-03,  2.0592e-02,  2.7110e-33, -5.1858e-02,\n",
       "          5.7836e-02, -9.1899e-02,  3.9442e-02,  1.0558e-01, -1.9691e-02,\n",
       "          6.1840e-02, -7.6347e-02,  2.4088e-02,  9.4005e-02, -1.1654e-01,\n",
       "          3.7120e-02,  5.2243e-02, -3.9586e-03,  5.7221e-02,  5.3286e-03,\n",
       "          1.2402e-01,  1.3902e-02, -1.1025e-02,  3.5605e-02, -3.3075e-02,\n",
       "          8.1657e-02, -1.5200e-02,  6.0559e-02, -6.0140e-02,  3.2610e-02,\n",
       "         -3.4830e-02, -1.6988e-02, -9.7491e-02, -2.7148e-02,  1.7471e-03,\n",
       "         -7.6898e-02, -4.3186e-02, -1.8999e-02, -2.9166e-02,  5.7749e-02,\n",
       "          2.4182e-02, -1.1690e-02, -6.2144e-02,  2.8435e-02, -2.3753e-04,\n",
       "         -2.5178e-02,  4.3964e-03,  8.1284e-02,  3.6418e-02, -6.0401e-02,\n",
       "         -3.6552e-02, -7.9375e-02, -5.0853e-03,  6.6970e-02, -1.1778e-01,\n",
       "          3.2374e-02, -4.7125e-02, -1.3446e-02, -9.4844e-02,  8.2495e-03,\n",
       "         -1.0675e-02, -6.8188e-02,  1.1182e-03,  2.4802e-02, -6.3589e-02,\n",
       "          2.8449e-02, -2.6130e-02,  8.5811e-02,  1.1468e-01, -5.3535e-02,\n",
       "         -5.6359e-02,  4.2601e-02,  1.0945e-02,  2.0958e-02,  1.0013e-01,\n",
       "          3.2605e-02, -1.8421e-01, -3.9321e-02, -6.9146e-02, -6.3811e-02,\n",
       "         -6.5639e-02, -6.4125e-03, -4.7961e-02, -7.6813e-02,  2.9538e-02,\n",
       "         -2.2995e-02,  4.1704e-02, -2.5005e-02, -4.5451e-03, -4.1714e-02,\n",
       "         -1.3229e-02, -6.3836e-02, -2.4647e-03, -1.3734e-02,  1.6898e-02,\n",
       "         -6.3040e-02,  8.9888e-02,  4.1817e-02, -1.8569e-02, -1.8044e-08,\n",
       "         -1.6800e-02, -3.2158e-02,  6.3038e-02, -4.1309e-02,  4.4482e-02,\n",
       "          2.0246e-03,  6.2959e-02, -5.1737e-03, -1.0044e-02, -3.0564e-02,\n",
       "          3.5267e-02,  5.5858e-02, -4.6713e-02,  3.4510e-02,  3.2958e-02,\n",
       "          4.3011e-02,  2.9436e-02, -3.0316e-02, -1.7111e-02,  7.3748e-02,\n",
       "         -5.4791e-02,  2.7752e-02,  6.2017e-03,  1.5880e-02,  3.4298e-02,\n",
       "         -5.1575e-03,  2.3508e-02,  7.5314e-02,  1.9284e-02,  3.3620e-02,\n",
       "          5.0910e-02,  1.5250e-01,  1.6421e-02,  2.7053e-02,  3.7516e-02,\n",
       "          2.1855e-02,  5.6633e-02, -3.9575e-02,  7.1231e-02, -5.4138e-02,\n",
       "          1.0377e-03,  2.1185e-02, -3.5631e-02,  1.0902e-01,  2.7654e-03,\n",
       "          3.1400e-02,  1.3842e-03, -3.4574e-02, -4.5928e-02,  2.8808e-02,\n",
       "          7.1690e-03,  4.8468e-02,  2.6102e-02, -9.4407e-03,  2.8217e-02,\n",
       "          3.4872e-02,  3.6910e-02, -8.5895e-03, -3.5321e-02, -2.4786e-02,\n",
       "         -1.9192e-02,  3.8071e-02,  5.9965e-02, -4.2229e-02]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "sentence_embeddings = F.normalize(sentence_embeddings)\n",
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.7657e-02,  6.3496e-02,  4.8713e-02,  7.9305e-02,  3.7448e-02,\n",
       "         2.6528e-03,  3.9375e-02, -7.0984e-03,  5.9361e-02,  3.1537e-02,\n",
       "         6.0098e-02, -5.2905e-02,  4.0607e-02, -2.5931e-02,  2.9843e-02,\n",
       "         1.1269e-03,  7.3515e-02, -5.0382e-02, -1.2239e-01,  2.3703e-02,\n",
       "         2.9727e-02,  4.2477e-02,  2.5634e-02,  1.9952e-03, -5.6919e-02,\n",
       "        -2.7160e-02, -3.2904e-02,  6.6025e-02,  1.1901e-01, -4.5879e-02,\n",
       "        -7.2621e-02, -3.2584e-02,  5.2341e-02,  4.5055e-02,  8.2530e-03,\n",
       "         3.6702e-02, -1.3941e-02,  6.5392e-02, -2.6427e-02,  2.0642e-04,\n",
       "        -1.3664e-02, -3.6281e-02, -1.9504e-02, -2.8974e-02,  3.9427e-02,\n",
       "        -8.8409e-02,  2.6243e-03,  1.3671e-02,  4.8306e-02, -3.1157e-02,\n",
       "        -1.1733e-01, -5.1169e-02, -8.8529e-02, -2.1896e-02,  1.4299e-02,\n",
       "         4.4417e-02, -1.3482e-02,  7.4339e-02,  2.6638e-02, -1.9876e-02,\n",
       "         1.7919e-02, -1.0605e-02, -9.0426e-02,  2.1327e-02,  1.4120e-01,\n",
       "        -6.4717e-03, -1.4038e-03, -1.5361e-02, -8.7357e-02,  7.2217e-02,\n",
       "         2.0140e-02,  4.2559e-02, -3.4901e-02,  3.1953e-04, -8.0297e-02,\n",
       "        -3.2747e-02,  2.8527e-02, -5.1366e-02,  1.0939e-01,  8.1933e-02,\n",
       "        -9.8404e-02, -9.3410e-02, -1.5129e-02,  4.5125e-02,  4.9417e-02,\n",
       "        -2.5187e-02,  1.5708e-02, -1.2929e-01,  5.3189e-03,  4.0234e-03,\n",
       "        -2.3457e-02, -6.7298e-02,  2.9228e-02, -2.6085e-02,  1.3063e-02,\n",
       "        -3.1166e-02, -4.8271e-02, -5.5886e-02, -3.8751e-02,  1.2001e-01,\n",
       "        -1.0392e-02,  4.8971e-02,  5.5354e-02,  4.4936e-02, -4.0098e-03,\n",
       "        -1.0296e-01, -2.9297e-02, -5.8340e-02,  2.7047e-02, -2.2017e-02,\n",
       "        -7.2224e-02, -4.1387e-02, -1.9330e-02,  2.7333e-03,  2.7700e-04,\n",
       "        -9.6759e-02, -1.0057e-01, -1.4192e-02, -8.0789e-02,  4.5393e-02,\n",
       "         2.4504e-02,  5.9761e-02, -7.3818e-02,  1.1984e-02, -6.6340e-02,\n",
       "        -7.6904e-02,  3.8516e-02, -5.5936e-33,  2.8001e-02, -5.6079e-02,\n",
       "        -4.8660e-02,  2.1557e-02,  6.0198e-02, -4.8140e-02, -3.5025e-02,\n",
       "         1.9331e-02, -1.7515e-02, -3.8921e-02, -3.8106e-03, -1.7029e-02,\n",
       "         2.8210e-02,  1.2829e-02,  4.7160e-02,  6.2103e-02, -6.4359e-02,\n",
       "         1.2929e-01, -1.3123e-02,  5.2307e-02, -3.7368e-02,  2.8909e-02,\n",
       "        -1.6898e-02, -2.3733e-02, -3.3349e-02, -5.1676e-02,  1.5536e-02,\n",
       "         2.0880e-02, -1.2537e-02,  4.5958e-02,  3.7272e-02,  2.8057e-02,\n",
       "        -5.9000e-02, -1.1699e-02,  4.9218e-02,  4.7033e-02,  7.3549e-02,\n",
       "        -3.7053e-02,  3.9846e-03,  1.0641e-02, -1.6148e-04, -5.2717e-02,\n",
       "         2.7593e-02, -3.9292e-02,  8.4472e-02,  4.8686e-02, -4.8588e-03,\n",
       "         1.7995e-02, -4.2857e-02,  1.2338e-02,  6.3996e-03,  4.0482e-02,\n",
       "         1.4889e-02, -1.5394e-02,  7.6295e-02,  2.3704e-02,  4.4524e-02,\n",
       "         5.0820e-02, -2.3125e-03, -1.8874e-02, -1.2334e-02,  4.6600e-02,\n",
       "        -5.6344e-02,  6.2993e-02, -3.1554e-02,  3.2491e-02,  2.3467e-02,\n",
       "        -6.5544e-02,  2.0171e-02,  2.5708e-02, -1.2387e-02, -8.3649e-03,\n",
       "        -6.6438e-02,  9.4307e-02, -3.5709e-02, -3.4248e-02, -6.6636e-03,\n",
       "        -8.0152e-03, -3.0971e-02,  4.3301e-02, -8.2140e-03, -1.5080e-01,\n",
       "         3.0769e-02,  4.0072e-02, -3.7929e-02,  1.9321e-03,  4.0053e-02,\n",
       "        -8.7708e-02, -3.6849e-02,  8.5796e-03, -3.1925e-02, -1.2526e-02,\n",
       "         7.3554e-02,  1.3474e-03,  2.0592e-02,  2.7110e-33, -5.1858e-02,\n",
       "         5.7836e-02, -9.1899e-02,  3.9442e-02,  1.0558e-01, -1.9691e-02,\n",
       "         6.1840e-02, -7.6347e-02,  2.4088e-02,  9.4005e-02, -1.1654e-01,\n",
       "         3.7120e-02,  5.2243e-02, -3.9586e-03,  5.7221e-02,  5.3286e-03,\n",
       "         1.2402e-01,  1.3902e-02, -1.1025e-02,  3.5605e-02, -3.3075e-02,\n",
       "         8.1657e-02, -1.5200e-02,  6.0559e-02, -6.0140e-02,  3.2610e-02,\n",
       "        -3.4830e-02, -1.6988e-02, -9.7491e-02, -2.7148e-02,  1.7471e-03,\n",
       "        -7.6898e-02, -4.3186e-02, -1.8999e-02, -2.9166e-02,  5.7749e-02,\n",
       "         2.4182e-02, -1.1690e-02, -6.2144e-02,  2.8435e-02, -2.3753e-04,\n",
       "        -2.5178e-02,  4.3964e-03,  8.1284e-02,  3.6418e-02, -6.0401e-02,\n",
       "        -3.6552e-02, -7.9375e-02, -5.0853e-03,  6.6970e-02, -1.1778e-01,\n",
       "         3.2374e-02, -4.7125e-02, -1.3446e-02, -9.4844e-02,  8.2495e-03,\n",
       "        -1.0675e-02, -6.8188e-02,  1.1182e-03,  2.4802e-02, -6.3589e-02,\n",
       "         2.8449e-02, -2.6130e-02,  8.5811e-02,  1.1468e-01, -5.3535e-02,\n",
       "        -5.6359e-02,  4.2601e-02,  1.0945e-02,  2.0958e-02,  1.0013e-01,\n",
       "         3.2605e-02, -1.8421e-01, -3.9321e-02, -6.9146e-02, -6.3811e-02,\n",
       "        -6.5639e-02, -6.4125e-03, -4.7961e-02, -7.6813e-02,  2.9538e-02,\n",
       "        -2.2995e-02,  4.1704e-02, -2.5005e-02, -4.5451e-03, -4.1714e-02,\n",
       "        -1.3229e-02, -6.3836e-02, -2.4647e-03, -1.3734e-02,  1.6898e-02,\n",
       "        -6.3040e-02,  8.9888e-02,  4.1817e-02, -1.8569e-02, -1.8044e-08,\n",
       "        -1.6800e-02, -3.2158e-02,  6.3038e-02, -4.1309e-02,  4.4482e-02,\n",
       "         2.0246e-03,  6.2959e-02, -5.1737e-03, -1.0044e-02, -3.0564e-02,\n",
       "         3.5267e-02,  5.5858e-02, -4.6713e-02,  3.4510e-02,  3.2958e-02,\n",
       "         4.3011e-02,  2.9436e-02, -3.0316e-02, -1.7111e-02,  7.3748e-02,\n",
       "        -5.4791e-02,  2.7752e-02,  6.2017e-03,  1.5880e-02,  3.4298e-02,\n",
       "        -5.1575e-03,  2.3508e-02,  7.5314e-02,  1.9284e-02,  3.3620e-02,\n",
       "         5.0910e-02,  1.5250e-01,  1.6421e-02,  2.7053e-02,  3.7516e-02,\n",
       "         2.1855e-02,  5.6633e-02, -3.9575e-02,  7.1231e-02, -5.4138e-02,\n",
       "         1.0377e-03,  2.1185e-02, -3.5631e-02,  1.0902e-01,  2.7654e-03,\n",
       "         3.1400e-02,  1.3842e-03, -3.4574e-02, -4.5928e-02,  2.8808e-02,\n",
       "         7.1690e-03,  4.8468e-02,  2.6102e-02, -9.4407e-03,  2.8217e-02,\n",
       "         3.4872e-02,  3.6910e-02, -8.5895e-03, -3.5321e-02, -2.4786e-02,\n",
       "        -1.9192e-02,  3.8071e-02,  5.9965e-02, -4.2229e-02])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.leebutterman.com/2023/06/01/offline-realtime-embedding-search.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
